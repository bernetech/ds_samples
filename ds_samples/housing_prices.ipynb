{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# You can use this function to help you visualize the dataset by\n",
    "# plotting a scatterplot of the data points in the training and \n",
    "# test sets.\n",
    "def data_scatter():\n",
    "    plt.figure()\n",
    "    plt.scatter(X_train, y_train, label='training data')\n",
    "    plt.scatter(X_test, y_test, label='test data')\n",
    "    plt.legend(loc=4);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.dummy import DummyRegressor\n",
    "\n",
    "    dumr = DummyRegressor(random_state=0).fit(X_train, y_train, random_state=0) \n",
    "    y_pred = dumr.predict(X_test)\n",
    "    accuracy = dumr.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    lr = LinearRegression(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    accuracy = lr.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    \n",
    "    dtr = DecisionTreeRegressor(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = dtr.predict(X_test)\n",
    "    accuracy = dtr.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsvr(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.svm import LinearSVR\n",
    "    \n",
    "    ## tried multiple values of epsilon, C, and max_iter, this was the best all-around\n",
    "    svr = LinearSVR(epsilon=7.0, max_iter=25000, random_state=0).fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    accuracy = svr.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    rfr = RandomForestRegressor(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = rfr.predict(X_test)\n",
    "    accuracy = rfr.score(X_test, y_test)\n",
    "        \n",
    "    return accuracy, rfr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnetcv(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    " \n",
    "    elastic = ElasticNetCV(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = elastic.predict(X_test)\n",
    "    accuracy = elastic.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradboostr(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(loss='huber', random_state=0).fit(X_train, y_train)\n",
    "    y_pred = gbr.predict(X_test)\n",
    "    accuracy = gbr.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy, gbr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticnetcv accuracy 0.6097868127909412\n",
      "gradient boost accuracy 0.8470396239319556\n",
      "rf features = [5.56006180e-03 2.25513036e-03 1.02244262e-02 1.98162643e-02\n",
      " 5.52099522e-01 5.89637407e-03 1.43158931e-02 8.73309945e-03\n",
      " 6.01614321e-03 3.35055525e-02 7.65093476e-04 1.14896044e-02\n",
      " 6.10157112e-02 2.84026414e-02 1.39559998e-02 3.15262616e-04\n",
      " 1.08835394e-01 1.87359529e-03 9.89268058e-05 1.19277434e-02\n",
      " 1.13937409e-03 2.18069581e-03 1.50822415e-03 5.38740170e-03\n",
      " 3.61093930e-03 3.90005624e-03 4.34701571e-02 1.65331823e-02\n",
      " 7.56314090e-03 6.74344607e-03 8.72745346e-04 6.03345711e-04\n",
      " 1.01117632e-03 1.89949176e-03 2.57528357e-04 3.88793433e-03\n",
      " 2.32872151e-03]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "df = pd.read_csv('kaggle_data/housing_prices/train.csv')\n",
    "\n",
    "## last column is SalePrice\n",
    "#X = df.iloc[:,:-1]\n",
    "#y = df.iloc[:,-1]\n",
    "\n",
    "X = df.drop('SalePrice', axis=1).select_dtypes(include=np.number).fillna(method='pad')\n",
    "y = df['SalePrice']\n",
    "\n",
    "#for i in X.columns:\n",
    "#    print(i)\n",
    "#    X.boxplot(i)\n",
    "#X.boxplot('GrLivArea')\n",
    "#df.boxplot(column=['GrLivArea', 'SalePrice'], by=['GrLivArea', 'SalePrice'])\n",
    "#print(X)\n",
    "#plt.scatter(df['GrLivArea'], df['SalePrice'])\n",
    "#print(df.columns)\n",
    "#print(X.isnull().any())\n",
    "#print(df.isnull().any())\n",
    "#mask = df.isnull().any()\n",
    "#print(df[mask])\n",
    "#print(df['GrLivArea'].isnull().values.any())\n",
    "#print(df.select_dtypes(include=np.number).columns.tolist())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#dummy_acc = dummy(X_train, X_test, y_train, y_test)\n",
    "#print('dummy accuracy {}'.format(dummy_accuracy))\n",
    "\n",
    "#lr_acc = linear(X_train, X_test, y_train, y_test)\n",
    "#print('linreg accuracy {}'.format(lr_accuracy))\n",
    "\n",
    "#dtree_acc = dtree(X_train, X_test, y_train, y_test)\n",
    "#print('decision tree accuracy {}'.format(dtree_acc))\n",
    "\n",
    "#lsvr_acc = lsvr(X_train, X_test, y_train, y_test)\n",
    "#print('linear svr accuracy {}'.format(lsvr_acc))\n",
    "\n",
    "#forest_acc, features = forest(X_train, X_test, y_train, y_test)\n",
    "#print('random forest accuracy {}\\nrf features = {}'.format(forest_acc, features))\n",
    "\n",
    "elastic_acc = elasticnetcv(X_train, X_test, y_train, y_test)\n",
    "print('elasticnetcv accuracy {}'.format(elastic_acc))\n",
    "\n",
    "gbr_acc, features = forest(X_train, X_test, y_train, y_test)\n",
    "print('gradient boost accuracy {}\\nrf features = {}'.format(gbr_acc, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After several regression attempts, here is where we stand:\n",
    "\n",
    "dummy accuracy -0.004215356514296831\n",
    "\n",
    "linreg accuracy 0.845238256233396\n",
    "\n",
    "decision tree accuracy 0.7513986464931918\n",
    "\n",
    "/opt/local/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "  \"the number of iterations.\", ConvergenceWarning)\n",
    "\n",
    "linear svr accuracy 0.7833024663262996 (Note: even 100000 iterations wouldn't cause convergence and caused a significant performance hit)\n",
    "\n",
    "random forest accuracy 0.8876702337541585\n",
    "\n",
    "Using all available numeric features, random forest had the best performance.  Let's look at the features matrix and see if we can improve.\n",
    "\n",
    "rf features = [5.65055600e-03 2.61743992e-03 8.29474732e-03 1.65907144e-02\n",
    " 5.34916000e-01 7.94490826e-03 1.90727908e-02 1.16484421e-02\n",
    " 5.66639186e-03 3.07818677e-02 1.28532766e-03 5.88879760e-03\n",
    " 4.84956089e-02 2.39524916e-02 2.48394537e-02 1.35899061e-04\n",
    " 1.02698970e-01 1.61407768e-03 5.16137384e-04 3.68547716e-02\n",
    " 1.09450105e-03 2.79271380e-03 1.47221849e-03 9.69403140e-03\n",
    " 3.84308848e-03 7.25384867e-03 3.17161371e-02 2.57665845e-02\n",
    " 7.55365244e-03 8.63709137e-03 9.09261469e-04 2.93131725e-05\n",
    " 2.39966230e-03 1.21728929e-03 1.25745813e-04 3.57667773e-03\n",
    " 2.45278950e-03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('OverallQual', 0.5666104398132453), ('GrLivArea', 0.10957266578573359), ('2ndFlrSF', 0.061582772112435874), ('TotalBsmtSF', 0.042163529897644506), ('BsmtFinSF1', 0.027559134495085104), ('GarageCars', 0.02196983539719794), ('GarageArea', 0.019016392095852663), ('1stFlrSF', 0.018304950287835423), ('LotArea', 0.0166241651402906), ('TotRmsAbvGrd', 0.016168252642821818), ('YearBuilt', 0.01292013693903154), ('YearRemodAdd', 0.008335435336106265), ('WoodDeckSF', 0.006864357625358476), ('LotFrontage', 0.006780317346362397), ('FullBath', 0.006628586616341492), ('BsmtUnfSF', 0.006444955211772373), ('MasVnrArea', 0.006118387654575188), ('OpenPorchSF', 0.006081224258221462), ('GarageYrBlt', 0.005911896152371462), ('Id', 0.005471759807879635), ('MoSold', 0.004573631683240575), ('BedroomAbvGr', 0.004313627261976569), ('OverallCond', 0.0042571518485906654), ('Fireplaces', 0.0036797287819329526), ('MSSubClass', 0.002271037707919765), ('YrSold', 0.0016987110449768455), ('KitchenAbvGr', 0.0014946379083835635), ('HalfBath', 0.0012796637597442754), ('BsmtFullBath', 0.0010453737612233726), ('ScreenPorch', 0.0010095244768921925), ('BsmtHalfBath', 0.0008507916647747881), ('EnclosedPorch', 0.000788334977056329), ('PoolArea', 0.0005291116322479154), ('3SsnPorch', 0.0004125599732629404), ('BsmtFinSF2', 0.0003343713537552519), ('LowQualFinSF', 0.00026080016048460244), ('MiscVal', 7.17473873743013e-05)])\n"
     ]
    }
   ],
   "source": [
    "_, features = forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "feat_combined = dict(zip(X_train.columns.tolist(), features))\n",
    "feat_sorted = {k: v for k, v in sorted(feat_combined.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(feat_sorted.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated random forest accuracy 0.7905828930126959\n"
     ]
    }
   ],
   "source": [
    "## as a first attempt, grab anything > 2% from the feature matrix\n",
    "X_pared = X[['OverallQual', 'GrLivArea', 'FullBath', 'TotalBsmtSF', 'BsmtFinSF1', 'GarageCars',\n",
    "             '1stFlrSF', 'GarageArea', '2ndFlrSF']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pared, y)\n",
    "\n",
    "accuracy, features = forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('updated random forest accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('OverallQual', 0.6117654810434219), ('GrLivArea', 0.12055752468431058), ('GarageArea', 0.06081046626698066), ('BsmtFinSF1', 0.04777846292977682), ('TotalBsmtSF', 0.045470915109885615), ('1stFlrSF', 0.03966704370971478), ('GarageCars', 0.028193822733468283), ('2ndFlrSF', 0.02548322352056971), ('FullBath', 0.02027306000187162)])\n"
     ]
    }
   ],
   "source": [
    "_, features = forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "feat_combined = dict(zip(X_train.columns.tolist(), features))\n",
    "feat_sorted = {k: v for k, v in sorted(feat_combined.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(feat_sorted.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated random forest accuracy 0.8947175261712093\n"
     ]
    }
   ],
   "source": [
    "X_pared = X_pared[['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'BsmtFinSF1']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pared, y)\n",
    "\n",
    "accuracy, features = forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('updated random forest accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('OverallQual', 0.5731529917059552), ('GrLivArea', 0.22562009660193214), ('TotalBsmtSF', 0.11381959190615322), ('BsmtFinSF1', 0.08740731978595953)])\n"
     ]
    }
   ],
   "source": [
    "_, features = forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "feat_combined = dict(zip(X_train.columns.tolist(), features))\n",
    "feat_sorted = {k: v for k, v in sorted(feat_combined.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(feat_sorted.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated random forest accuracy 0.6670652544809061\n"
     ]
    }
   ],
   "source": [
    "X_pared = X_pared[['OverallQual', 'GrLivArea', 'TotalBsmtSF']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pared, y)\n",
    "\n",
    "accuracy, features = forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('updated random forest accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated random forest accuracy 0.8465771315310303\n"
     ]
    }
   ],
   "source": [
    "X_pared = X[['OverallQual', 'GrLivArea', 'FullBath', 'TotalBsmtSF', 'BsmtFinSF1', 'GarageCars']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pared, y)\n",
    "\n",
    "accuracy, features = forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('updated random forest accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kaggle_data/housing_prices/test.csv')\n",
    "\n",
    "X = df[['OverallQual', 'GrLivArea', 'FullBath', 'TotalBsmtSF', 'BsmtFinSF1', \n",
    "        'GarageCars']].fillna(method='pad')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=0).fit(X_train, y_train)\n",
    "df['SalePrice'] = rfr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['Id', 'SalePrice']].to_csv('/tmp/kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OverallQual', 'GrLivArea', 'FullBath', 'TotalBsmtSF', 'BsmtFinSF1', 'GarageCars']\n",
      "elasticnetcv accuracy 0.48219387777684314\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns.tolist())\n",
    "elastic_acc = elasticnetcv(X_train, X_test, y_train, y_test)\n",
    "print('elasticnetcv accuracy {}'.format(elastic_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad boost accuracy 0.8791900377484874\n"
     ]
    }
   ],
   "source": [
    "#gbr_acc = gradboostr(X_train, X_test, y_train, y_test)\n",
    "#print('grad boost accuracy {}'.format(gbr_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('OverallQual', 0.5154542675236976), ('GrLivArea', 0.13771175849114348), ('GarageCars', 0.061298505276699826), ('TotalBsmtSF', 0.05855551632851086), ('BsmtFinSF1', 0.04868429561983262), ('2ndFlrSF', 0.04529697737871447), ('YearBuilt', 0.02468268682997965), ('YearRemodAdd', 0.019040534309661367), ('LotArea', 0.016351133811191347), ('1stFlrSF', 0.015706626084122464), ('FullBath', 0.01088987500648837), ('Fireplaces', 0.007662309556526603), ('OverallCond', 0.0074616515031735485), ('TotRmsAbvGrd', 0.006060084111234475), ('OpenPorchSF', 0.0035839668638652806), ('GarageArea', 0.0035217329832654843), ('ScreenPorch', 0.0032391612723503024), ('GarageYrBlt', 0.002786282525587487), ('BsmtFullBath', 0.0018757176333741184), ('BsmtUnfSF', 0.0017947998676083091), ('KitchenAbvGr', 0.0013473944022614087), ('WoodDeckSF', 0.00112842579766904), ('MoSold', 0.001063013105091824), ('BsmtFinSF2', 0.0009076067692292859), ('PoolArea', 0.0008004991145531229), ('HalfBath', 0.000530751077926752), ('YrSold', 0.00043618717168920543), ('LotFrontage', 0.0004265000721496417), ('BedroomAbvGr', 0.0003724340589490623), ('MSSubClass', 0.00036188883511753707), ('Id', 0.00035444708694329374), ('MasVnrArea', 0.0002702894415433601), ('LowQualFinSF', 0.00015405238435599168), ('3SsnPorch', 7.144342465054674e-05), ('BsmtHalfBath', 5.682734683242129e-05), ('EnclosedPorch', 5.6083276392207446e-05), ('MiscVal', 4.2736576176203374e-06)])\n"
     ]
    }
   ],
   "source": [
    "_, features = gradboostr(X_train, X_test, y_train, y_test)\n",
    "\n",
    "feat_combined = dict(zip(X_train.columns.tolist(), features))\n",
    "feat_sorted = {k: v for k, v in sorted(feat_combined.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(feat_sorted.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated grad boost accuracy 0.8574744805562833\n",
      "dict_items([('OverallQual', 0.5336887064402109), ('GrLivArea', 0.16235252078879192), ('TotalBsmtSF', 0.07668922974369871), ('GarageCars', 0.07020422369749897), ('2ndFlrSF', 0.059749482339350346), ('BsmtFinSF1', 0.051005514904444785), ('YearBuilt', 0.04631032208600431)])\n"
     ]
    }
   ],
   "source": [
    "X_pared = X[['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'BsmtFinSF1', '2ndFlrSF', 'YearBuilt']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pared, y)\n",
    "\n",
    "accuracy, features = gradboostr(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('updated grad boost accuracy {}'.format(accuracy))\n",
    "\n",
    "feat_combined = dict(zip(X_train.columns.tolist(), features))\n",
    "feat_sorted = {k: v for k, v in sorted(feat_combined.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(feat_sorted.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated grad boost accuracy 0.7520001237528543\n",
      "dict_items([('OverallQual', 0.5823069425760106), ('GrLivArea', 0.14118905296491216), ('TotalBsmtSF', 0.09369946652662942), ('GarageCars', 0.06454825155415404), ('BsmtFinSF1', 0.06370052993447567), ('2ndFlrSF', 0.05455575644381823)])\n"
     ]
    }
   ],
   "source": [
    "X_pared = X[['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'BsmtFinSF1', '2ndFlrSF']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pared, y)\n",
    "\n",
    "accuracy, features = gradboostr(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('updated grad boost accuracy {}'.format(accuracy))\n",
    "\n",
    "feat_combined = dict(zip(X_train.columns.tolist(), features))\n",
    "feat_sorted = {k: v for k, v in sorted(feat_combined.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(feat_sorted.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated grad boost accuracy 0.7529251382981808\n",
      "dict_items([('OverallQual', 0.6076816252335124), ('GrLivArea', 0.1750351633739493), ('TotalBsmtSF', 0.08213322177019274), ('BsmtFinSF1', 0.0710304411288883), ('GarageCars', 0.06411954849345727)])\n"
     ]
    }
   ],
   "source": [
    "X_pared = X[['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'BsmtFinSF1']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pared, y)\n",
    "\n",
    "accuracy, features = gradboostr(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('updated grad boost accuracy {}'.format(accuracy))\n",
    "\n",
    "feat_combined = dict(zip(X_train.columns.tolist(), features))\n",
    "feat_sorted = {k: v for k, v in sorted(feat_combined.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(feat_sorted.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated grad boost accuracy 0.8628115577947024\n",
      "dict_items([('OverallQual', 0.5584434563712902), ('GrLivArea', 0.20338427166251172), ('TotalBsmtSF', 0.16141655153087203), ('GarageCars', 0.07675572043532598)])\n"
     ]
    }
   ],
   "source": [
    "X_pared = X[['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pared, y)\n",
    "\n",
    "accuracy, features = gradboostr(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('updated grad boost accuracy {}'.format(accuracy))\n",
    "\n",
    "feat_combined = dict(zip(X_train.columns.tolist(), features))\n",
    "feat_sorted = {k: v for k, v in sorted(feat_combined.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(feat_sorted.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated grad boost accuracy 0.8548070214288086\n",
      "dict_items([('OverallQual', 0.6249209939108168), ('GrLivArea', 0.1947659429081298), ('TotalBsmtSF', 0.1073844198611878), ('BsmtFinSF1', 0.07292864331986565)])\n"
     ]
    }
   ],
   "source": [
    "X_pared = X[['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'BsmtFinSF1']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pared, y)\n",
    "\n",
    "accuracy, features = gradboostr(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('updated grad boost accuracy {}'.format(accuracy))\n",
    "\n",
    "feat_combined = dict(zip(X_train.columns.tolist(), features))\n",
    "feat_sorted = {k: v for k, v in sorted(feat_combined.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(feat_sorted.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kaggle_data/housing_prices/test.csv')\n",
    "\n",
    "X = df[['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'BsmtFinSF1']].fillna(method='pad')\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "    \n",
    "gbr = GradientBoostingRegressor(random_state=0).fit(X_train, y_train)\n",
    "df['SalePrice'] = gbr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Id', 'SalePrice']].to_csv('/tmp/kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
